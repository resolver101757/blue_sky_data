{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProfileViewDetailed(did='did:plc:oc7nomnf7bsgmraom72ts3fp', handle='alex-paul-kelly.bsky.social', associated=ProfileAssociated(chat=None, feedgens=0, labeler=False, lists=0, starter_packs=0, py_type='app.bsky.actor.defs#profileAssociated'), avatar='https://cdn.bsky.app/img/avatar/plain/did:plc:oc7nomnf7bsgmraom72ts3fp/bafkreiasgk56xkl76blphf7uo2yprnv45smrs56w4vouxphmaav6jibpzm@jpeg', banner=None, created_at='2024-11-19T13:11:41.438Z', description=None, display_name='', followers_count=15, follows_count=313, indexed_at='2024-11-19T13:11:41.438Z', joined_via_starter_pack=None, labels=[], pinned_post=None, posts_count=5, viewer=ViewerState(blocked_by=False, blocking=None, blocking_by_list=None, followed_by=None, following=None, known_followers=KnownFollowers(count=8, followers=[ProfileViewBasic(did='did:plc:5hkogxu5u4wkelj6qm6iarip', handle='aisupremacy.bsky.social', associated=None, avatar='https://cdn.bsky.app/img/avatar/plain/did:plc:5hkogxu5u4wkelj6qm6iarip/bafkreicianwa7fzkz5dcgnb344oaaerpgnn54253gq4fb3vb3rsdke6z7e@jpeg', created_at='2023-05-14T04:51:30.932Z', display_name='Michael Kevin Spencer', labels=[], viewer=ViewerState(blocked_by=False, blocking=None, blocking_by_list=None, followed_by='at://did:plc:5hkogxu5u4wkelj6qm6iarip/app.bsky.graph.follow/3lbopxwal2v2z', following='at://did:plc:oc7nomnf7bsgmraom72ts3fp/app.bsky.graph.follow/3lbov7pq5l32i', known_followers=None, muted=False, muted_by_list=None, py_type='app.bsky.actor.defs#viewerState'), py_type='app.bsky.actor.defs#profileViewBasic'), ProfileViewBasic(did='did:plc:agq4mh5ivxmxgqcjyw5k653m', handle='rolando-sgarcia.bsky.social', associated=None, avatar='https://cdn.bsky.app/img/avatar/plain/did:plc:agq4mh5ivxmxgqcjyw5k653m/bafkreid3ec3qwdh4hh66ixgwnwsxr6kngmqbtphqrisl26ne336772qk7m@jpeg', created_at='2024-09-03T19:35:45.240Z', display_name='Rolando Garcia', labels=[], viewer=ViewerState(blocked_by=False, blocking=None, blocking_by_list=None, followed_by='at://did:plc:agq4mh5ivxmxgqcjyw5k653m/app.bsky.graph.follow/3lbkqw5zmwn2d', following='at://did:plc:oc7nomnf7bsgmraom72ts3fp/app.bsky.graph.follow/3lbkno7f3lr2i', known_followers=None, muted=False, muted_by_list=None, py_type='app.bsky.actor.defs#viewerState'), py_type='app.bsky.actor.defs#profileViewBasic'), ProfileViewBasic(did='did:plc:xernvmowfmadetm5r57q4rqf', handle='johnowhitaker.bsky.social', associated=ProfileAssociated(chat=ProfileAssociatedChat(allow_incoming='all', py_type='app.bsky.actor.defs#profileAssociatedChat'), feedgens=None, labeler=None, lists=None, starter_packs=None, py_type='app.bsky.actor.defs#profileAssociated'), avatar=None, created_at='2023-10-01T03:41:40.916Z', display_name=None, labels=[], viewer=ViewerState(blocked_by=False, blocking=None, blocking_by_list=None, followed_by='at://did:plc:xernvmowfmadetm5r57q4rqf/app.bsky.graph.follow/3lbrwvnzbuj2a', following='at://did:plc:oc7nomnf7bsgmraom72ts3fp/app.bsky.graph.follow/3lbrxa2pxec2e', known_followers=None, muted=False, muted_by_list=None, py_type='app.bsky.actor.defs#viewerState'), py_type='app.bsky.actor.defs#profileViewBasic'), ProfileViewBasic(did='did:plc:wxg2qylyqgnk746bopio2aff', handle='benburtenshaw.bsky.social', associated=None, avatar='https://cdn.bsky.app/img/avatar/plain/did:plc:wxg2qylyqgnk746bopio2aff/bafkreidfvuhf54rlf34z77nhhsyf2owyc2jj7kxo57zhyonduymljoyrwu@jpeg', created_at='2024-11-13T18:07:00.110Z', display_name='Ben Burtenshaw', labels=[], viewer=ViewerState(blocked_by=False, blocking=None, blocking_by_list=None, followed_by='at://did:plc:wxg2qylyqgnk746bopio2aff/app.bsky.graph.follow/3lbsfmncskx2h', following='at://did:plc:oc7nomnf7bsgmraom72ts3fp/app.bsky.graph.follow/3lbsfp24v6b2q', known_followers=None, muted=False, muted_by_list=None, py_type='app.bsky.actor.defs#viewerState'), py_type='app.bsky.actor.defs#profileViewBasic'), ProfileViewBasic(did='did:plc:fbys5luib3cir4ba6arbio7m', handle='senorcarbone.bsky.social', associated=None, avatar='https://cdn.bsky.app/img/avatar/plain/did:plc:fbys5luib3cir4ba6arbio7m/bafkreicmf2cg4x77hdqk3l2hob26rs66tkpy4fpegflbdk2cacfw5y4z2a@jpeg', created_at='2023-12-24T20:07:47.961Z', display_name='Paris Carbone', labels=[], viewer=ViewerState(blocked_by=False, blocking=None, blocking_by_list=None, followed_by='at://did:plc:fbys5luib3cir4ba6arbio7m/app.bsky.graph.follow/3lbknrbjdsi2l', following='at://did:plc:oc7nomnf7bsgmraom72ts3fp/app.bsky.graph.follow/3lbknpeyi3g2o', known_followers=None, muted=False, muted_by_list=None, py_type='app.bsky.actor.defs#viewerState'), py_type='app.bsky.actor.defs#profileViewBasic')], py_type='app.bsky.actor.defs#knownFollowers'), muted=False, muted_by_list=None, py_type='app.bsky.actor.defs#viewerState'), py_type='app.bsky.actor.defs#profileViewDetailed')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from atproto import Client, client_utils\n",
    "from dotenv import load_dotenv\n",
    "import sqlite3\n",
    "import time \n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "username = os.getenv('username')\n",
    "password = os.getenv('password')\n",
    "\n",
    "client = Client()\n",
    "client.login(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database setup complete. Starting feed...\n"
     ]
    }
   ],
   "source": [
    "# Set up SQLite database\n",
    "conn = sqlite3.connect('bsky_posts.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create table if it doesn't exist\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS posts (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        author TEXT,\n",
    "        text TEXT\n",
    "    )\n",
    "''')\n",
    "conn.commit()\n",
    "\n",
    "print(\"Database setup complete. Starting feed...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of the most recent post we've seen\n",
    "last_seen_post = None\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Get the timeline\n",
    "        timeline = client.get_timeline(limit=50)  # Adjust limit as needed\n",
    "\n",
    "        # Iterate through posts, newest first\n",
    "        for post in reversed(timeline.feed):\n",
    "            # If we've seen this post before, skip to the next one\n",
    "            if last_seen_post and post.post.cid == last_seen_post:\n",
    "                break\n",
    "            \n",
    "            # Insert post into database\n",
    "            cursor.execute('''\n",
    "                INSERT INTO posts (author, text) VALUES (?, ?)\n",
    "            ''', (post.post.author.handle, post.post.record.text))\n",
    "            \n",
    "            # # Print post details\n",
    "            # print(f\"Author: {post.post.author.handle}\")\n",
    "            # print(f\"Text: {post.post.record.text}\")\n",
    "            # print(\"---\")\n",
    "\n",
    "        # Commit the changes to the database\n",
    "        conn.commit()\n",
    "\n",
    "        # Update the last seen post\n",
    "        if timeline.feed:\n",
    "            last_seen_post = timeline.feed[0].post.cid\n",
    "\n",
    "        # Wait for a bit before checking again\n",
    "        time.sleep(60)  # Wait for 60 seconds\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nExiting the feed loop...\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"Waiting before trying again...\")\n",
    "        time.sleep(300)  # Wait for 5 minutes before trying again\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "print(\"Database connection closed. Exiting program.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "conn = sqlite3.connect('bsky_posts.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Read all posts from the database\n",
    "cursor.execute('SELECT author, text FROM posts')\n",
    "posts = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts: 3884\n",
      "\n",
      "Sample of posts:\n",
      "Author: avt.im\n",
      "Text: A part of those dynamics is that more and more papers are getting submitted to ML venues, while other venues grow slower if at all.\n",
      "\n",
      "Even people who repeatedly complain about ML venues still submit there, even work they could instead send to various journals. This isnâ€™t by accident.\n",
      "--------------------------------------------------\n",
      "Author: neuripsconf.bsky.social\n",
      "Text: NeurIPS Conference is now Live on Bluesky! \n",
      "\n",
      "-NeurIPS2024 Communication Chairs\n",
      "--------------------------------------------------\n",
      "Author: merve.bsky.social\n",
      "Text: something small but might approaches\n",
      "--------------------------------------------------\n",
      "Author: nicoritschel.com\n",
      "Text: Metrics for when updating multiple similar queries is annoying.\n",
      "\n",
      "If code is more your thing, that's okay too & will be supported. Note the SQLâ€” there's no new expression language to learn.\n",
      "--------------------------------------------------\n",
      "Author: nsaphra.bsky.social\n",
      "Text: One of my favorite animations ever, but a bit distressing\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display the posts\n",
    "print(f\"Total posts: {len(posts)}\")\n",
    "print(\"\\nSample of posts:\")\n",
    "for post in posts[:5]:  # Show first 5 posts\n",
    "    author, text = post\n",
    "    print(f\"Author: {author}\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pass the data to a llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: False\n",
    "#| output: False\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key from environment variables\n",
    "google_api_key = os.getenv('google_api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=google_api_key)\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash-8b\",\n",
    "  generation_config=generation_config,\n",
    ")\n",
    "\n",
    "chat_session = model.start_chat(\n",
    "  history=[\n",
    "  ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bsky_posts = \"\"\n",
    "for post in posts[:5]:\n",
    "    my_bsky_posts += f\"Author: {post[0]}\\nText: {post[1]}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: avt.im\n",
      "Text: A part of those dynamics is that more and more papers are getting submitted to ML venues, while other venues grow slower if at all.\n",
      "\n",
      "Even people who repeatedly complain about ML venues still submit there, even work they could instead send to various journals. This isnâ€™t by accident.\n",
      "Author: neuripsconf.bsky.social\n",
      "Text: NeurIPS Conference is now Live on Bluesky! \n",
      "\n",
      "-NeurIPS2024 Communication Chairs\n",
      "Author: merve.bsky.social\n",
      "Text: something small but might approaches\n",
      "Author: nicoritschel.com\n",
      "Text: Metrics for when updating multiple similar queries is annoying.\n",
      "\n",
      "If code is more your thing, that's okay too & will be supported. Note the SQLâ€” there's no new expression language to learn.\n",
      "Author: nsaphra.bsky.social\n",
      "Text: One of my favorite animations ever, but a bit distressing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(my_bsky_posts) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_text = \"this is a list of posts from blue sky, please analyze the data and return a list of topics that are being discussed/n\" + my_bsky_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the BlueSky posts reveals these topics:\n",
      "\n",
      "1. **Machine Learning (ML) Conferences/Journals:**  The first post discusses the imbalance in submissions to ML venues versus other venues.  The NeurIPS post is a direct promotion of the conference.\n",
      "\n",
      "2. **Software/Database:** The post from `nicoritschel.com` deals with metrics and SQL, indicating a focus on software development and potentially database management.\n",
      "\n",
      "3. **Animation:** The post from `nsaphra.bsky.social` expresses a personal opinion about an animation.\n",
      "\n",
      "4. **Social Media/Platform:** The NeurIPS post specifically mentions using Bluesky, which highlights the context of social media presence.\n",
      "\n",
      "\n",
      "There isn't a single unifying theme across all posts, suggesting they were likely drawn from different discussions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat_session.send_message(llm_text)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
